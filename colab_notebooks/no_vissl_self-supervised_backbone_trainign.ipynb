{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"no_vissl_self-supervised_backbone_trainign.ipynb","provenance":[{"file_id":"1-4MHkPwcu7n1PLerIsO0wFcTzj45a9ws","timestamp":1624712531385}],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"view-in-github"},"source":["<a href=\"https://colab.research.google.com/github/DarioRugg/Self-Supervised_Pearson_Search/blob/pretrained_test/main_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"]},{"cell_type":"markdown","metadata":{"id":"wa0sXMAUQJks"},"source":["## Setup"]},{"cell_type":"markdown","metadata":{"id":"st3FR7gvQOuU"},"source":["### Path"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"J5NmBBQZsqDw","executionInfo":{"status":"ok","timestamp":1625473881955,"user_tz":-120,"elapsed":19266,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"53a93dfb-4337-4b74-cb90-05c2b457a250"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1bXl-JaFL7Qi","executionInfo":{"status":"ok","timestamp":1625473955423,"user_tz":-120,"elapsed":384,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"e54d2c58-135f-4ec9-f7f9-9ca0be8e0aea"},"source":["%cd /content/drive/MyDrive/PoE_Project/Self-Supervised_Pearson_Search/self_supervision/JigsawPuzzlePytorch/"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/drive/.shortcut-targets-by-id/1fmgF9LrJJENY7Hz3KuriiSG0gKv202-0/Code/Self-Supervised_Pearson_Search/self_supervision/JigsawPuzzlePytorch\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"GtGIkvajQdFt"},"source":["### Installing Libraries"]},{"cell_type":"markdown","metadata":{"id":"AgbGJuedWra_"},"source":["For VISSL"]},{"cell_type":"code","metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"T8XpF1igkfsb","outputId":"aa9cab80-a02d-40fb-c655-36c0c6decaa0"},"source":["!pip install --upgrade torch==1.6.0\n","!pip install --upgrade torchvision==0.7.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torch==1.6.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5d/5e/35140615fc1f925023f489e71086a9ecc188053d263d3594237281284d82/torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8MB)\n","\u001b[K     |████████████████████████████████| 748.8MB 24kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (0.16.0)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0) (1.19.5)\n","\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.6.0 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","Successfully installed torch-1.6.0\n","Collecting torchvision==0.7.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/b5/60d5eb61f1880707a5749fea43e0ec76f27dfe69391cdec953ab5da5e676/torchvision-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.9MB)\n","\u001b[K     |████████████████████████████████| 5.9MB 20.6MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.19.5)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (7.1.2)\n","Requirement already satisfied, skipping upgrade: torch==1.6.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0) (1.6.0)\n","Requirement already satisfied, skipping upgrade: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->torchvision==0.7.0) (0.16.0)\n","Installing collected packages: torchvision\n","  Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","Successfully installed torchvision-0.7.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7LF0W1QWmOZo","executionInfo":{"status":"ok","timestamp":1625471739065,"user_tz":-120,"elapsed":169847,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"2749b95c-c90b-4a57-88e3-5f962c5d0d69"},"source":["!pip install --upgrade torch==1.8.0\n","!pip install --upgrade torchvision==0.9.0"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting torch==1.8.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/94/99/5861239a6e1ffe66e120f114a4d67e96e5c4b17c1a785dfc6ca6769585fc/torch-1.8.0-cp37-cp37m-manylinux1_x86_64.whl (735.5MB)\n","\u001b[K     |████████████████████████████████| 735.5MB 24kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (1.19.5)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0) (3.7.4.3)\n","\u001b[31mERROR: torchvision 0.10.0+cu102 has requirement torch==1.9.0, but you'll have torch 1.8.0 which is incompatible.\u001b[0m\n","\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.8.0 which is incompatible.\u001b[0m\n","Installing collected packages: torch\n","  Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","Successfully installed torch-1.8.0\n","Collecting torchvision==0.9.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/6a/4e8d7c897f24a6aa9d5e7c23a157b52084ccd43d1b6019603361d2136dde/torchvision-0.9.0-cp37-cp37m-manylinux1_x86_64.whl (17.3MB)\n","\u001b[K     |████████████████████████████████| 17.3MB 202kB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (1.19.5)\n","Requirement already satisfied, skipping upgrade: torch==1.8.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (1.8.0)\n","Requirement already satisfied, skipping upgrade: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.9.0) (7.1.2)\n","Requirement already satisfied, skipping upgrade: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.0->torchvision==0.9.0) (3.7.4.3)\n","Installing collected packages: torchvision\n","  Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","Successfully installed torchvision-0.9.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"3a_Z5FV9RFHd","executionInfo":{"status":"ok","timestamp":1625470643446,"user_tz":-120,"elapsed":17211,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"c22d0e20-f938-442c-882e-bc4a2f3adfcb"},"source":["!pip install vissl"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting vissl\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/6f/e908efc4ab7e1d2178feb6a86c1d6955526e4f9da4d1d235779125940c04/vissl-0.1.5-py3-none-any.whl (754kB)\n","\u001b[K     |████████████████████████████████| 757kB 7.8MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.7/dist-packages (from vissl) (1.19.5)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from vissl) (0.29.23)\n","Collecting fairscale\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/33/61/036144395f9aae5d9c965e19c75768b6d95339b23311e90693a6517c9cec/fairscale-0.3.7.tar.gz (183kB)\n","\u001b[K     |████████████████████████████████| 184kB 16.6MB/s \n","\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n","    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from vissl) (0.8.9)\n","Collecting hydra-core>=1.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/cd/85aa2e3a8babc36feac99df785e54abf99afbc4acc20488630f3ef46980a/hydra_core-1.1.0-py3-none-any.whl (144kB)\n","\u001b[K     |████████████████████████████████| 153kB 28.1MB/s \n","\u001b[?25hCollecting faiss>=1.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ef/2e/dc5697e9ff6f313dcaf3afe5ca39d7d8334114cbabaed069d0026bbc3c61/faiss-1.5.3-cp37-cp37m-manylinux1_x86_64.whl (4.7MB)\n","\u001b[K     |████████████████████████████████| 4.7MB 26.8MB/s \n","\u001b[?25hCollecting parameterized==0.7.4\n","  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n","Collecting fvcore\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c9/67/1a386384816c6577a3d858a79f7ff697db176b71f5cb06ded0f2a3caeb8a/fvcore-0.1.5.post20210630.tar.gz (49kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.9MB/s \n","\u001b[?25hRequirement already satisfied: pycocotools>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from vissl) (2.0.2)\n","Collecting tensorboard==1.15.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n","\u001b[K     |████████████████████████████████| 3.8MB 43.4MB/s \n","\u001b[?25hRequirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from vissl) (0.22.2.post1)\n","Requirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from fairscale->vissl) (1.9.0+cu102)\n","Collecting omegaconf==2.1.*\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/96/1966b48bfe6ca64bfadfa7bcc9a8d73c5d83b4be769321fcc5d617abeb0c/omegaconf-2.1.0-py3-none-any.whl (74kB)\n","\u001b[K     |████████████████████████████████| 81kB 11.5MB/s \n","\u001b[?25hRequirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.7/dist-packages (from hydra-core>=1.0->vissl) (5.1.4)\n","Collecting antlr4-python3-runtime==4.8\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/56/02/789a0bddf9c9b31b14c3e79ec22b9656185a803dc31c15f006f9855ece0d/antlr4-python3-runtime-4.8.tar.gz (112kB)\n","\u001b[K     |████████████████████████████████| 112kB 57.8MB/s \n","\u001b[?25hCollecting yacs>=0.1.6\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Collecting pyyaml>=5.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7a/a5/393c087efdc78091afa2af9f1378762f9821c9c1d7a22c5753fb5ac5f97a/PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636kB)\n","\u001b[K     |████████████████████████████████| 645kB 47.8MB/s \n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (4.41.1)\n","Requirement already satisfied: termcolor>=1.1 in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (1.1.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from fvcore->vissl) (7.1.2)\n","Collecting iopath>=0.1.7\n","  Downloading https://files.pythonhosted.org/packages/af/20/65dd9bd25a1eb7fa35b5ae38d289126af065f8a0c1f6a90564f4bff0f89d/iopath-0.1.9-py3-none-any.whl\n","Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl) (3.2.2)\n","Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.7/dist-packages (from pycocotools>=2.0.1->vissl) (57.0.0)\n","Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.12.0)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (0.36.2)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.15.0)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.3.4)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.0.1)\n","Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (3.12.4)\n","Requirement already satisfied: grpcio>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard==1.15.0->vissl) (1.34.1)\n","Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.4.1)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->vissl) (1.0.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->fairscale->vissl) (3.7.4.3)\n","Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.7/dist-packages (from importlib-resources; python_version < \"3.9\"->hydra-core>=1.0->vissl) (3.4.1)\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.4.7)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (2.8.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (1.3.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.1.0->pycocotools>=2.0.1->vissl) (0.10.0)\n","Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard==1.15.0->vissl) (4.5.0)\n","Building wheels for collected packages: fairscale\n","  Building wheel for fairscale (PEP 517) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fairscale: filename=fairscale-0.3.7-cp37-none-any.whl size=231175 sha256=6e8e7d77b8bdec4fff1756a6a9105f79918b23d5c3dc8030053edbbc446015f0\n","  Stored in directory: /root/.cache/pip/wheels/3b/f6/2c/e530cf2c10ae9d9d9a033f91a62fea54cd8960ab78edeb7175\n","Successfully built fairscale\n","Building wheels for collected packages: fvcore, antlr4-python3-runtime\n","  Building wheel for fvcore (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fvcore: filename=fvcore-0.1.5.post20210630-cp37-none-any.whl size=60611 sha256=ebbafd9f78233deb96c4926b30222bbbd07f6d5b3e80e6f2c6fed759cc3cac00\n","  Stored in directory: /root/.cache/pip/wheels/b0/f7/36/05283055e1035eb8aedcdd7f816d46776979511769a2702908\n","  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.8-cp37-none-any.whl size=141231 sha256=2b8923932b1ff368c54c9b3435747fece0f2f5c0c0432575c0b0e1e20673557e\n","  Stored in directory: /root/.cache/pip/wheels/e3/e2/fa/b78480b448b8579ddf393bebd3f47ee23aa84c89b6a78285c8\n","Successfully built fvcore antlr4-python3-runtime\n","\u001b[31mERROR: tensorflow 2.5.0 has requirement tensorboard~=2.5, but you'll have tensorboard 1.15.0 which is incompatible.\u001b[0m\n","Installing collected packages: fairscale, pyyaml, antlr4-python3-runtime, omegaconf, hydra-core, faiss, parameterized, yacs, portalocker, iopath, fvcore, tensorboard, vissl\n","  Found existing installation: PyYAML 3.13\n","    Uninstalling PyYAML-3.13:\n","      Successfully uninstalled PyYAML-3.13\n","  Found existing installation: tensorboard 2.5.0\n","    Uninstalling tensorboard-2.5.0:\n","      Successfully uninstalled tensorboard-2.5.0\n","Successfully installed antlr4-python3-runtime-4.8 fairscale-0.3.7 faiss-1.5.3 fvcore-0.1.5.post20210630 hydra-core-1.1.0 iopath-0.1.9 omegaconf-2.1.0 parameterized-0.7.4 portalocker-2.3.0 pyyaml-5.4.1 tensorboard-1.15.0 vissl-0.1.5 yacs-0.1.8\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["pydevd_plugins"]}}},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"IPly-9cjV4TT"},"source":["Actually the suggestions on the [VISSL site](https://vissl.ai/) are to install many more packages; \\\\\n","But with just those it works."]},{"cell_type":"markdown","metadata":{"id":"NbEpG-ancDGU"},"source":["## Dataset \n","building the data catalog."]},{"cell_type":"markdown","metadata":{"id":"vcNlBaByQ490"},"source":["# Actual code"]},{"cell_type":"markdown","metadata":{"id":"BfJxuu_0Qz2K"},"source":["## Running the model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4AsH1Mgb0V2i","executionInfo":{"status":"ok","timestamp":1625481263842,"user_tz":-120,"elapsed":7629,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"1d208c32-f0e3-4857-82b0-69ba0fb1ba85"},"source":["!python JigsawTrain.py ../../data/PWR_self_supervised/ --gpu 0 --batch 32\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["Using GPU 0\n","Process number: 1722\n","Images: train 4563, validation 1141\n","Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n","100% 97.8M/97.8M [00:00<00:00, 217MB/s]\n","Start training: lr 0.001000, batch size 32, classes 1000\n","Checkpoint: checkpoints/\n","Learning Rate 0.001000\n","Traceback (most recent call last):\n","  File \"JigsawTrain.py\", line 198, in <module>\n","    main()\n","  File \"JigsawTrain.py\", line 135, in main\n","    outputs = net(images)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\", line 249, in forward\n","    return self._forward_impl(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torchvision/models/resnet.py\", line 232, in _forward_impl\n","    x = self.conv1(x)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\", line 1051, in _call_impl\n","    return forward_call(*input, **kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 443, in forward\n","    return self._conv_forward(input, self.weight, self.bias)\n","  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/modules/conv.py\", line 440, in _conv_forward\n","    self.padding, self.dilation, self.groups)\n","RuntimeError: Expected 4-dimensional input for 4-dimensional weight [64, 3, 7, 7], but got 5-dimensional input of size [32, 9, 3, 75, 75] instead\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"szrkLsPPT_b9"},"source":["Tests with resnet"]},{"cell_type":"code","metadata":{"id":"cj1lJdQaUHE4","executionInfo":{"status":"ok","timestamp":1625482625170,"user_tz":-120,"elapsed":650,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}}},"source":["import torch\n","import torch.nn as nn\n","from torch import cat\n","import torch.nn.init as init\n","import torchvision.models as models"],"execution_count":18,"outputs":[]},{"cell_type":"code","metadata":{"id":"IbdHEofcUMEr","executionInfo":{"status":"ok","timestamp":1625482696100,"user_tz":-120,"elapsed":640,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}}},"source":["res50_model = models.resnet50(pretrained=True)  "],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"qk_OH4u3UaEN","executionInfo":{"status":"ok","timestamp":1625482716108,"user_tz":-120,"elapsed":258,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}}},"source":["feature_extractor = nn.Sequential(*list(res50_model.children())[:-1])\n","pretrained_last_layers = nn.Sequential(*list(res50_model.children())[-1:])"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VazkF9A4UfUe","executionInfo":{"status":"ok","timestamp":1625482758870,"user_tz":-120,"elapsed":280,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"6eca2478-da83-4174-ef4d-2e3f4f5df015"},"source":["list(feature_extractor.children())"],"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False),\n"," BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True),\n"," ReLU(inplace=True),\n"," MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False),\n"," Sequential(\n","   (0): Bottleneck(\n","     (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","     (downsample): Sequential(\n","       (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","       (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     )\n","   )\n","   (1): Bottleneck(\n","     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (2): Bottleneck(\n","     (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n"," ),\n"," Sequential(\n","   (0): Bottleneck(\n","     (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","     (downsample): Sequential(\n","       (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","       (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     )\n","   )\n","   (1): Bottleneck(\n","     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (2): Bottleneck(\n","     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (3): Bottleneck(\n","     (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n"," ),\n"," Sequential(\n","   (0): Bottleneck(\n","     (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","     (downsample): Sequential(\n","       (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","       (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     )\n","   )\n","   (1): Bottleneck(\n","     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (2): Bottleneck(\n","     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (3): Bottleneck(\n","     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (4): Bottleneck(\n","     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (5): Bottleneck(\n","     (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n"," ),\n"," Sequential(\n","   (0): Bottleneck(\n","     (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","     (downsample): Sequential(\n","       (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n","       (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     )\n","   )\n","   (1): Bottleneck(\n","     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n","   (2): Bottleneck(\n","     (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n","     (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n","     (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","     (relu): ReLU(inplace=True)\n","   )\n"," ),\n"," AdaptiveAvgPool2d(output_size=(1, 1))]"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xbcL-1P8UuHp","executionInfo":{"status":"ok","timestamp":1625482804137,"user_tz":-120,"elapsed":5,"user":{"displayName":"dario ruggeri","photoUrl":"","userId":"00605556345834424824"}},"outputId":"c923de28-4c08-4690-eec7-053d364750d7"},"source":["list(pretrained_last_layers.children())"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[Linear(in_features=2048, out_features=1000, bias=True)]"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"code","metadata":{"id":"85nCqWAWT_CG"},"source":["class Network(nn.Module):\n","\n","    def __init__(self, classes=1000):\n","        super(Network, self).__init__()\n","\n","        res50_model = models.resnet50(pretrained=True)        \n","        self.feature_extractor = nn.Sequential(*list(res50_model.children())[:-1])\n","        self.pretrained_last_layers = nn.Sequential(*list(res50_model.children())[-1:])\n","\n","        self.classifier = nn.Sequential()\n","        self.classifier.add_module('final_fc',nn.Linear(2048*9, classes))\n","\n","    def save(self,checkpoint):\n","        res50_model_finetuned = nn.Sequential([self.feature_extractor, self.pretrained_last_layers])\n","        torch.save(res50_model_finetuned.state_dict(), checkpoint)\n","    \n","    def forward(self, x):\n","        B,T,C,H,W = x.size()\n","        x = x.transpose(0,1)\n","\n","        x_list = []\n","        for i in range(9):\n","            z = self.feature_extractor(x[i])\n","            z = z.view([B,1,-1])\n","            x_list.append(z)\n","\n","        x = cat(x_list,1)\n","        x = self.fc7(x.view(B,-1))\n","        x = self.classifier(x)\n","\n","        return x\n","\n","\n","def weights_init(model):\n","    if type(model) in [nn.Conv2d,nn.Linear]:\n","        nn.init.xavier_normal(model.weight.data)\n","        nn.init.constant(model.bias.data, 0.1)\n","    "],"execution_count":null,"outputs":[]}]}